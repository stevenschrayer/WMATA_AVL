{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Decomposition Methods: Metro Transit Approach Applied to Wisconsin TSP\r\n",
    "\r\n",
    "Produced by Wylie Timmerman with the WMATA Datamart Bus Priority Team\r\n",
    "Draft: July 16, 2021\r\n",
    "\r\n",
    "## Introduction\r\n",
    "\r\n",
    "In this notebook, we'll see the application of the Metro Transit decomposition approach to Wisconsin Avenue bus routes, along with some light comparisons of pre- and post-TSP decomposition values.\r\n",
    "\r\n",
    "## Environment Setup\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Libraries\r\n",
    "import os, sys, glob, pandas as pd, geopandas as gpd\r\n",
    "from dotenv import dotenv_values\r\n",
    "import pyarrow as pa\r\n",
    "import pyarrow.parquet as pq\r\n",
    "import datetime as dt\r\n",
    "from itertools import product\r\n",
    "import numpy as np\r\n",
    "from plotly.offline import plot\r\n",
    "import plotly.graph_objs as go\r\n",
    "import plotly.express as px\r\n",
    "import plotly as py\r\n",
    "py.offline.init_notebook_mode()\r\n",
    "py.io.renderers.default='notebook'\r\n",
    "import statsmodels.formula.api as smf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Paths\r\n",
    "os.environ[\"GDAL_DATA\"] = os.environ[\"CONDA_PREFIX\"] + \"\\Library\\share\\gdal\"\r\n",
    "path_working = r\"C:\\Users\\WylieTimmerman\\Documents\\projects_local\\WMATA_AVL_datamart\"\r\n",
    "os.chdir(os.path.join(path_working))\r\n",
    "sys.path.append(r\"C:\\Users\\WylieTimmerman\\Documents\\projects_local\\WMATA_AVL_datamart\")\r\n",
    "path_sp = r\"C:\\OD\\Foursquare ITP\\Projects - WMATA Datamart\\Task 3 - Bus Priority\"\r\n",
    "path_source_data = os.path.join(path_sp,\"data\",\"00-Raw\")\r\n",
    "path_processed_data = os.path.join(path_sp, \"data\",\"02-Processed\")\r\n",
    "# Server credentials\r\n",
    "config = dotenv_values(os.path.join(path_working, '.env'))\r\n",
    "\r\n",
    "# Globals\r\n",
    "wmata_crs = 2248\r\n",
    "\r\n",
    "# Load wmatarawnav library\r\n",
    "import wmatarawnav as wr"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll load previously decomposed trips on Wisconsin Avenue routes 30N, 30S, 33, and 31 from February through May 2021. Each record in the loaded table is uniquely defined by :\r\n",
    "\r\n",
    "* Trip Instance (identified by *filename* and *index_run_start*)\r\n",
    "* Trip Segment (identified by *trip_seg*: either the stop window area +/-150 ft from stop, or the segment between these windows)\r\n",
    "* Travel Time Decomposition (identified by *full_decomp*: this column differentiates between freeflow and delay in non-passenger time)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rawnav_run_decomp = (\r\n",
    "    pq.read_table(\r\n",
    "        source=os.path.join(path_sp,\"data\",\"01-Interim\",\"wisconsin_decomp_mt.parquet\"),\r\n",
    "        use_pandas_metadata = True\r\n",
    "    )\r\n",
    "    .to_pandas()\r\n",
    "    # As a bit of proofing, we confirm this is int32\r\n",
    "    .reset_index()\r\n",
    ")\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll filter to data between February 1st and April 30th."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# We parsed through the end of may, but want a month and a half on each end only.\r\n",
    "rawnav_run_decomp = (\r\n",
    "    rawnav_run_decomp\r\n",
    "    .loc[\r\n",
    "        (rawnav_run_decomp.start_date_time.dt.tz_localize(None) < np.datetime64('2021-04-30')) &\r\n",
    "        (rawnav_run_decomp.start_date_time.dt.tz_localize(None) >= np.datetime64('2021-02-01')) # the february files include some january 31 dates\r\n",
    "    ]\r\n",
    ")\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below we show the first 10 records belonging to one trip instance in particular. Note that in some cases delay values may be negative. This is because we've calculated freeflow as the 95th percentile of travel time through a stop; as a result, some trip instances will cover the area faster than freeflow speed."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rawnav_run_decomp.head(10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Prep for Analysis\r\n",
    "\r\n",
    "Next, we'll add identifiers to trips that will be useful for our analysis; in particular, whether a trip is in general eligible to receive TSP based on its route, direction, time period, and service day. We'll use March 15, 2021 as the breakpoint for when TSP is activated or not. We'll perform data quality checks at the end of this process.\r\n",
    "\r\n",
    "The table below shows categories of trips that may receive TSP; even though Metrobus Route 31 won't receive TSP, we want to pick analogous directions and times for the comparison. We'll also define an 'off-direction' for the TSP peak-direction/peak-time so that we can compare changes in these cases against the direction and time eligible for TSP."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO: add additional identifiers somehow for if the vehicle is on wisconsin\r\n",
    "# TODO: Update to reflect that periods defined not on trip start time, but time when vehicle reached a TSP intersection.\r\n",
    "\r\n",
    "tsp_conditions = wr.tribble(\r\n",
    "        ['route','direction_wmata_schedule', 'service_day','time_period','tsp_dir_time', 'tsp_offdir_time'],\r\n",
    "        \"30N\",                       \"EAST\",     \"Weekday\",    \"AM Peak\",           True,            False,\r\n",
    "        \"30N\",                       \"WEST\",     \"Weekday\",    \"PM Peak\",           True,            False,\r\n",
    "        \"30S\",                       \"EAST\",     \"Weekday\",    \"AM Peak\",           True,            False,\r\n",
    "        \"30S\",                       \"WEST\",     \"Weekday\",    \"PM Peak\",           True,            False,\r\n",
    "         \"33\",                      \"SOUTH\",     \"Weekday\",    \"AM Peak\",           True,            False,\r\n",
    "         \"33\",                      \"NORTH\",     \"Weekday\",    \"PM Peak\",           True,            False,\r\n",
    "         \"31\",                      \"SOUTH\",     \"Weekday\",    \"AM Peak\",           True,            False,\r\n",
    "         \"31\",                      \"NORTH\",     \"Weekday\",    \"PM Peak\",           True,            False,\r\n",
    "        \"30N\",                       \"WEST\",     \"Weekday\",    \"AM Peak\",           False,            True,\r\n",
    "        \"30N\",                       \"EAST\",     \"Weekday\",    \"PM Peak\",           False,            True,\r\n",
    "        \"30S\",                       \"WEST\",     \"Weekday\",    \"AM Peak\",           False,            True,\r\n",
    "        \"30S\",                       \"EAST\",     \"Weekday\",    \"PM Peak\",           False,            True,\r\n",
    "         \"33\",                      \"NORTH\",     \"Weekday\",    \"AM Peak\",           False,            True,\r\n",
    "         \"33\",                      \"SOUTH\",     \"Weekday\",    \"PM Peak\",           False,            True,\r\n",
    "         \"31\",                      \"NORTH\",     \"Weekday\",    \"AM Peak\",           False,            True,\r\n",
    "         \"31\",                      \"SOUTH\",     \"Weekday\",    \"PM Peak\",           False,            True\r\n",
    "    )\r\n",
    "\r\n",
    "tsp_conditions"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The steps below are those used to add these TSP identifiers and others to the data.\r\n",
    "\r\n",
    "We'll also defined a set of holidays during the analysis period to convert to sunday or saturdays, respectively. We won't distinguish saturday and saturday supplemental service here."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rawnav_run_decomp_2 = (\r\n",
    "    rawnav_run_decomp\r\n",
    "    .assign(\r\n",
    "        is_tsp_route = lambda x: x.route.isin(['30N','30S','33']),\r\n",
    "        tsp_period = lambda x: \r\n",
    "            np.where(\r\n",
    "                x.start_date_time.dt.tz_localize(None) < np.datetime64('2021-03-15'),\r\n",
    "                \"pre_tsp\",\r\n",
    "                \"post_tsp\"\r\n",
    "            ),\r\n",
    "        dow = lambda x: x.start_date_time.dt.dayofweek,\r\n",
    "        service_day = lambda x: \r\n",
    "            np.select(\r\n",
    "                [\r\n",
    "                    x.dow.isin([0,1,2,3,4]),\r\n",
    "                    x.dow.eq(5),\r\n",
    "                    x.dow.eq(6)\r\n",
    "                ],\r\n",
    "                [\r\n",
    "                    'Weekday',\r\n",
    "                    'Saturday',\r\n",
    "                    'Sunday'\r\n",
    "                ]\r\n",
    "            )\r\n",
    "    )\r\n",
    "    .assign(\r\n",
    "        service_day = lambda x:\r\n",
    "            # we'll set President's day to saturday \r\n",
    "            np.where(\r\n",
    "                x.start_date_time.dt.tz_localize(None) == np.datetime64('2021-02-15'),\r\n",
    "                'Saturday',\r\n",
    "                x.service_day\r\n",
    "            ),\r\n",
    "        trip_hour = lambda x: x.start_date_time.dt.hour,\r\n",
    "        # TODO: double check timestamps/timezone on conversion back from \r\n",
    "        # numpy\r\n",
    "        time_period = lambda x: \r\n",
    "            pd.cut(\r\n",
    "                x.trip_hour,\r\n",
    "                bins = pd.IntervalIndex.from_tuples(\r\n",
    "                    [\r\n",
    "                        (0,4),\r\n",
    "                        (4,6),\r\n",
    "                        (6,9),\r\n",
    "                        (9,15),\r\n",
    "                        (15,19),\r\n",
    "                        (19,23),\r\n",
    "                        (23,999)\r\n",
    "                    ]\r\n",
    "                ),\r\n",
    "                include_lowest=True, \r\n",
    "                retbins = False\r\n",
    "            )\r\n",
    "            .astype(\"category\")\r\n",
    "            .cat.rename_categories(\r\n",
    "                ['Late Night1',\r\n",
    "                'Early AM',\r\n",
    "                'AM Peak',\r\n",
    "                'Midday',\r\n",
    "                'PM Peak',\r\n",
    "                'Evening',\r\n",
    "                'Late Night2']\r\n",
    "            )\r\n",
    "    )\r\n",
    "    .merge(\r\n",
    "        tsp_conditions,\r\n",
    "        on = ['route','direction_wmata_schedule', 'service_day','time_period'],\r\n",
    "        how = \"left\"\r\n",
    "    )\r\n",
    "    .assign(\r\n",
    "        tsp_dir_time = lambda x : x.tsp_dir_time.fillna(False),\r\n",
    "        overall_dir = lambda x : \r\n",
    "            np.where(\r\n",
    "                x.direction_wmata_schedule.isin(['EAST','SOUTH']),\r\n",
    "                \"Southbound\",\r\n",
    "                \"Northbound\"\r\n",
    "            )\r\n",
    "    )\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A sample of the decomposition values with these additional identifers are shown below."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rawnav_run_decomp_2.head(100)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we'll also filter to the trips and stops that are on the Wisconsin corridor and have data for the complete set of stops on this corridor; at a later date, we will evalutate entire routes. Because of what we've found with GPS errors around the terminal, we'll drop the terminal at Friendship Heights as a corridor stop after we import the list of corridor stops."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "wisconsin_corr_stops = (\r\n",
    "    pd.read_csv(os.path.join(path_processed_data,\"wisconsin_corridor_stops.csv\"))\r\n",
    "    .query('stop_id != 32089')\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "wisconsin_corr_stops.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "wisconsin_corr_grp = wisconsin_corr_stops.groupby(['route','direction'])\r\n",
    "rawnav_run_decomp_2_grp = rawnav_run_decomp_2.groupby(['route','direction_wmata_schedule','filename','index_run_start'])\r\n",
    "\r\n",
    "rawnav_run_decomp_2_wisc = pd.DataFrame()\r\n",
    "\r\n",
    "trips_missing_stops = pd.DataFrame()\r\n",
    "\r\n",
    "for name, rawnav_group in rawnav_run_decomp_2_grp:\r\n",
    "    # try:\r\n",
    "    wisconsin_corr_rtdir_stops = (\r\n",
    "        wisconsin_corr_grp\r\n",
    "        .get_group((name[0], name[1]))\r\n",
    "        .stop_id\r\n",
    "        .astype(str)\r\n",
    "    )\r\n",
    "    \r\n",
    "    rawnav_group_stops = (\r\n",
    "        rawnav_group\r\n",
    "        # filter to just the stops\r\n",
    "        .query('(basic_decomp == \"Non-Passenger\") | (basic_decomp == \"Passenger\")')\r\n",
    "        .trip_seg\r\n",
    "    )\r\n",
    "\r\n",
    "    miss_stops = list(set(wisconsin_corr_rtdir_stops) - set(rawnav_group_stops))\r\n",
    "\r\n",
    "    if (len(miss_stops) == 0):\r\n",
    "        # if you have all the corridor stops, then we'll filter to those stops and keep\r\n",
    "        # that decomposition. Later we may want to separate this part out\r\n",
    "        # this regex is a little bespoke, but so i think we'll need to use a different approach for parsing stops and stop segs in the future\r\n",
    "\r\n",
    "        stop_regex = r\"(?:^|_)[^\\d]*(?:\" + \"|\".join(wisconsin_corr_rtdir_stops) + \")\"\r\n",
    "\r\n",
    "        rawnav_group_out = (\r\n",
    "            rawnav_group\r\n",
    "            .loc[rawnav_group.trip_seg.str.contains(stop_regex, na = False)]\r\n",
    "        )\r\n",
    "\r\n",
    "        rawnav_run_decomp_2_wisc = pd.concat([rawnav_run_decomp_2_wisc, rawnav_group_out])\r\n",
    "    else:\r\n",
    "        trip_miss_deets = pd.DataFrame({\"filename\" : name[2], \"index_run_start\" : name[3], 'route' : name[0],'direction_wmata_schedule' : name[1], \"miss_stop\" : miss_stops})\r\n",
    "        trips_missing_stops = pd.concat([trips_missing_stops,trip_miss_deets])\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Where did we lose trips? What were the stops that didn't join? if it was mostly 32089, then it's mostly join issue at the terminal and we shouldn't be too worried. But maybe we should filter that out first, not sure..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "count_missing_stops = (\r\n",
    "    trips_missing_stops\r\n",
    "    .groupby(['miss_stop'])\r\n",
    "    .agg(count = ('miss_stop','count'))\r\n",
    ")\r\n",
    "\r\n",
    "count_missing_stops"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we'll modify this a bit further to remove the portions of routes that are arriving or departing from the bus terminal at Western Ave. Until further processing steps to cleanly identify the start and end of a trip are developed, it is better to exclude these portions of the route from the analysis. Even though we excluded the terminal from our corridor stops earlier, this next step will also remove the segments leading to and from the terminal."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rawnav_run_decomp_2_fil = (\r\n",
    "    rawnav_run_decomp_2_wisc\r\n",
    "    #stop id for friendship heights bay used by these buses; this will remove segments leading to and from as well\r\n",
    "    .loc[~rawnav_run_decomp_2_wisc.trip_seg.str.contains('32089', na = False)] \r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll aggregate to the trip-level to do some reasonableness filtering on trip instances, keeping all trips with total corridor runtimes between the 1st and 99th percentile."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trip_times = (\r\n",
    "    rawnav_run_decomp_2_fil\r\n",
    "    .groupby(['filename','index_run_start'])\r\n",
    "    .agg(\r\n",
    "        tot_secs = ('secs_tot','sum')\r\n",
    "    )\r\n",
    ")\r\n",
    "\r\n",
    "trip_times_dist = (\r\n",
    "    trip_times\r\n",
    "    .agg(\r\n",
    "        tot_secs_min = ('tot_secs','min'),\r\n",
    "        tot_secs_p01 = ('tot_secs', lambda x: x.quantile(.01)),\r\n",
    "        tot_secs_p05 = ('tot_secs', lambda x: x.quantile(.05)),\r\n",
    "        tot_secs_p50 = ('tot_secs', lambda x: x.quantile(.50)),\r\n",
    "        tot_secs_p95 = ('tot_secs', lambda x: x.quantile(.95)),\r\n",
    "        tot_secs_p99 = ('tot_secs', lambda x: x.quantile(.99)),\r\n",
    "        tot_secs_max = ('tot_secs', 'max'),\r\n",
    "    )\r\n",
    ")\r\n",
    "\r\n",
    "trip_times_dist"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trip_times_low = (\r\n",
    "    trip_times_dist\r\n",
    "    .loc['tot_secs_p01','tot_secs']\r\n",
    ")\r\n",
    "\r\n",
    "trip_times_high = (\r\n",
    "    trip_times_dist\r\n",
    "    .loc['tot_secs_p99','tot_secs']\r\n",
    ")\r\n",
    "\r\n",
    "trip_times_fil = (\r\n",
    "    trip_times\r\n",
    "    .loc[(trip_times.tot_secs >= trip_times_low) & (trip_times.tot_secs <= trip_times_high)]\r\n",
    "    .reset_index()\r\n",
    ")\r\n",
    "\r\n",
    "rawnav_run_decomp_2_fil = (\r\n",
    "    rawnav_run_decomp_2_fil\r\n",
    "    .merge(\r\n",
    "        trip_times_fil,\r\n",
    "        how = 'right',\r\n",
    "        on = ['filename','index_run_start']\r\n",
    "    )\r\n",
    "    .reindex(rawnav_run_decomp_2_fil.columns, axis = \"columns\")\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "removed = trip_times.shape[0] - trip_times_fil.shape[0]\r\n",
    "print('by filtering to trips between the first and 99th percentile in runtimes, ' + str(removed) + ' trips were removed.')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rawnav_run_decomp_trip = (\r\n",
    "    rawnav_run_decomp_2_fil \r\n",
    "    .groupby(\r\n",
    "        ['filename',\r\n",
    "        'index_run_start',\r\n",
    "        'full_decomp']\r\n",
    "    )\r\n",
    "    .agg(\r\n",
    "        tot_secs = ('secs_tot','sum')\r\n",
    "    )\r\n",
    "    .reset_index()\r\n",
    ")\r\n",
    "\r\n",
    "trip_details = (\r\n",
    "    rawnav_run_decomp_2_fil\r\n",
    "    .filter(\r\n",
    "        [\r\n",
    "            'filename',\r\n",
    "            'index_run_start',\r\n",
    "            'route',\r\n",
    "            'direction_wmata_schedule',\r\n",
    "            'pattern_destination_wmata_schedule',\r\n",
    "            'overall_dir',\r\n",
    "            'is_tsp_route',\r\n",
    "            'time_period',\r\n",
    "            'service_day',\r\n",
    "            'start_date_time',\r\n",
    "            'tsp_period',\r\n",
    "            'tsp_dir_time'\r\n",
    "        ],\r\n",
    "        axis =  \"columns\"\r\n",
    "    )\r\n",
    "    .drop_duplicates()\r\n",
    ")\r\n",
    "\r\n",
    "rawnav_run_decomp_trip_2 = (\r\n",
    "    rawnav_run_decomp_trip\r\n",
    "    .merge(\r\n",
    "        trip_details,\r\n",
    "        on = ['filename','index_run_start'],\r\n",
    "        how = 'left'\r\n",
    "    )\r\n",
    ")\r\n",
    "\r\n",
    "rawnav_run_decomp_trip_2.head()\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rawnav_run_decomp_trip_2.to_csv(\"rawnav_run_decomp_trip_2.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Quality Checks\r\n",
    "\r\n",
    "### Counts of Trips\r\n",
    "Before we begin analysis, we'll perform a few additional filtering steps to ensure we're reviewing trips without outlier values for speed, distance traveled, or travel time."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "How many total trips do we capture in the rawnav data?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "check_val = (\r\n",
    "    rawnav_run_decomp\r\n",
    "    .filter(items = ['filename','index_run_start'])\r\n",
    "    .drop_duplicates()\r\n",
    "    .shape[0]\r\n",
    ")\r\n",
    "\r\n",
    "print(\"Number of 30N/30S/33/31 trips in parsed rawnav data: \" + str(check_val))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "What about trips with data on the Wisconsin corridor?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "check_val = (\r\n",
    "    rawnav_run_decomp_trip_2\r\n",
    "    .filter(items = ['filename','index_run_start'])\r\n",
    "    .drop_duplicates()\r\n",
    "    .shape[0]\r\n",
    ")\r\n",
    "\r\n",
    "print(\"Number of 30N/30S/33/31 trips with data on the corridor: \" + str(check_val))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Runtime Comparisons to Trace\r\n",
    "\r\n",
    "What is the runtime we see on the corridor? Does it approximately match what we see in Scott's data?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "last_study = wr.tribble(\r\n",
    "    [   'routes','direction',      'time',\t'median',\t'n95th'],\r\n",
    "            '31',\t    'NB',\t'PM Peak',\t    12.8,\t   17.3,\r\n",
    "    '30N/30S/33',\t    'NB',\t'PM Peak',\t    13.6,\t   17.7,\r\n",
    "            '31',\t    'SB',\t'AM Peak',\t    11.1,\t   14.9,\r\n",
    "    '30N/30S/33',\t    'SB',\t'AM Peak',\t    10.8,\t   14.4\r\n",
    ")\r\n",
    "\r\n",
    "last_study"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trip_times_posttsp = (\r\n",
    "    rawnav_run_decomp_trip_2\r\n",
    "    .loc[\r\n",
    "        (rawnav_run_decomp_trip_2.tsp_dir_time == True) & \r\n",
    "        (rawnav_run_decomp_trip_2.tsp_period == \"post_tsp\") & \r\n",
    "        (rawnav_run_decomp_trip_2.start_date_time.dt.tz_localize(None) <= np.datetime64('2021-04-15')) # to match previous analysis\r\n",
    "    ]\r\n",
    "    .assign(\r\n",
    "        gen_dir = lambda x: \r\n",
    "            np.where(\r\n",
    "                x.direction_wmata_schedule.isin(['EAST','SOUTH']),\r\n",
    "                \"SB\",\r\n",
    "                \"NB\"\r\n",
    "            )\r\n",
    "    )\r\n",
    "    .groupby(['filename','index_run_start','is_tsp_route','overall_dir','time_period'])\r\n",
    "    .agg(\r\n",
    "        tot_secs = ('tot_secs','sum')\r\n",
    "    )\r\n",
    "    .reset_index()\r\n",
    "    .assign(\r\n",
    "        tot_mins = lambda x: x.tot_secs / 60\r\n",
    "    )\r\n",
    "    .groupby(['is_tsp_route','overall_dir','time_period'])\r\n",
    "    .agg(\r\n",
    "        tot_mins_p50 = ('tot_mins', lambda x: x.quantile(.50)),\r\n",
    "        tot_mins_p95 = ('tot_mins', lambda x: x.quantile(.95))\r\n",
    "    )\r\n",
    "    .reset_index()\r\n",
    "    .assign(\r\n",
    "        route_names = lambda x: \r\n",
    "            np.where(\r\n",
    "                x.is_tsp_route,\r\n",
    "                \"30N/30S/33\",\r\n",
    "                \"31\"\r\n",
    "            )\r\n",
    "    )\r\n",
    "    .drop(columns = 'is_tsp_route')\r\n",
    ")\r\n",
    "trip_times_posttsp"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "These values seem a little high relative to the last study. What if we remove passenger activity to get at runtime?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# for convenience, we'll just copy the code chunk but add the filter earlier\r\n",
    "trip_times_posttsp_nopax = (\r\n",
    "    rawnav_run_decomp_trip_2\r\n",
    "    .loc[\r\n",
    "        (rawnav_run_decomp_trip_2.tsp_dir_time == True) & \r\n",
    "        (rawnav_run_decomp_trip_2.tsp_period == \"post_tsp\") & \r\n",
    "        (rawnav_run_decomp_trip_2.start_date_time.dt.tz_localize(None) <= np.datetime64('2021-04-15')) &\r\n",
    "        (rawnav_run_decomp_trip_2.full_decomp != \"Passenger\")\r\n",
    "    ]\r\n",
    "    .groupby(['filename','index_run_start','is_tsp_route','overall_dir','time_period'])\r\n",
    "    .agg(\r\n",
    "        tot_secs = ('tot_secs','sum')\r\n",
    "    )\r\n",
    "    .reset_index()\r\n",
    "    .assign(\r\n",
    "        tot_mins = lambda x: x.tot_secs / 60\r\n",
    "    )\r\n",
    "    .groupby(['is_tsp_route','overall_dir','time_period'])\r\n",
    "    .agg(\r\n",
    "        tot_mins_p50 = ('tot_mins', lambda x: x.quantile(.50)),\r\n",
    "        tot_mins_p95 = ('tot_mins', lambda x: x.quantile(.95))\r\n",
    "    )\r\n",
    "    .reset_index()\r\n",
    "    .assign(\r\n",
    "        route_names = lambda x: \r\n",
    "            np.where(\r\n",
    "                x.is_tsp_route,\r\n",
    "                \"30N/30S/33\",\r\n",
    "                \"31\"\r\n",
    "            )\r\n",
    "    )\r\n",
    "    .drop(columns = 'is_tsp_route')\r\n",
    ")\r\n",
    "trip_times_posttsp_nopax"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "These values without dwell time/passenger time are still a little higher than the previous study, but not significantly. The remaining difference might be attributed to how the corridor is defined."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Runtime Trends\r\n",
    "Do we see parallel trends in median runtimes week by week? "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trip_times_trends = (\r\n",
    "    rawnav_run_decomp_trip_2\r\n",
    "    .loc[(rawnav_run_decomp_trip_2.tsp_dir_time == True) & (rawnav_run_decomp_trip_2.full_decomp != \"Passenger\")]\r\n",
    "    .assign(\r\n",
    "        start_date = lambda x: x.start_date_time.dt.round(freq = \"24H\"),\r\n",
    "        weekgroup = lambda x: x.start_date - pd.to_timedelta(x.start_date.dt.dayofweek, unit = 'd')\r\n",
    "    )\r\n",
    "    .groupby(['filename','index_run_start','is_tsp_route','overall_dir','time_period','tsp_period','weekgroup'])\r\n",
    "    .agg(\r\n",
    "        tot_secs = ('tot_secs','sum')\r\n",
    "    )\r\n",
    "    .reset_index()\r\n",
    "    .assign(\r\n",
    "        tot_mins = lambda x: x.tot_secs / 60\r\n",
    "    )\r\n",
    "    .groupby(['is_tsp_route','tsp_period','weekgroup'])\r\n",
    "    .agg(\r\n",
    "        tot_mins_avg = ('tot_mins','mean'),\r\n",
    "        tot_mins_p50 = ('tot_mins', lambda x: x.quantile(.50)),\r\n",
    "        tot_mins_p95 = ('tot_mins', lambda x: x.quantile(.95))\r\n",
    "    )\r\n",
    "    .reset_index()\r\n",
    "    .assign(\r\n",
    "        route_names = lambda x: \r\n",
    "            np.where(\r\n",
    "                x.is_tsp_route,\r\n",
    "                \"30N/30S/33\",\r\n",
    "                \"31\"\r\n",
    "            )\r\n",
    "    )\r\n",
    "    .sort_values(['is_tsp_route','weekgroup'])\r\n",
    ")\r\n",
    "\r\n",
    "trip_times_trends"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig0 = px.line(\r\n",
    "    trip_times_trends,\r\n",
    "    x = \"weekgroup\",\r\n",
    "    y = \"tot_mins_avg\",\r\n",
    "    color = \"route_names\",\r\n",
    "    labels={ # replaces default labels by column name\r\n",
    "        \"route_names\": \"Routes\",  \r\n",
    "        \"tot_mins_avg\" : \"Total Time (Average)\",\r\n",
    "        \"weekgroup\" : \"Week\"\r\n",
    "    },\r\n",
    "    template = \"simple_white\"\r\n",
    ")\r\n",
    "\r\n",
    "fig0.update_layout(\r\n",
    "    font=dict(\r\n",
    "        size=18\r\n",
    "    )\r\n",
    ")\r\n",
    "\r\n",
    "py.offline.iplot(fig0, filename='Overtime')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Descriptive Stats\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trip Level\r\n",
    "How have median values for the decomposition at the trip level changed by route, direction, and period?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rawnav_run_decomp_agg = (\r\n",
    "    rawnav_run_decomp_trip_2 \r\n",
    "    # let's first summarize to trip level \r\n",
    "    .loc[rawnav_run_decomp_trip_2.tsp_dir_time == True]\r\n",
    "    .drop(['tsp_dir_time'], axis = 'columns')\r\n",
    "    .groupby(['route','direction_wmata_schedule','tsp_period','full_decomp'])\r\n",
    "    .agg({\r\n",
    "        'tot_secs' : [lambda x: x.quantile(.50)],\r\n",
    "        'filename' : ['count']\r\n",
    "    })\r\n",
    "    .pipe(wr.reset_col_names)\r\n",
    "    .query(\"full_decomp != 'End of Trip Pings'\")\r\n",
    "    .rename(\r\n",
    "        columns = {\r\n",
    "            \"tot_secs_<lambda>\" : \"tot_secs_med\",\r\n",
    "            \"filename_count\" : \"n_count\"\r\n",
    "        }\r\n",
    "    )\r\n",
    ")\r\n",
    "\r\n",
    "rawnav_run_decomp_agg['tot_secs_pct'] = (\r\n",
    "    rawnav_run_decomp_agg\r\n",
    "    .groupby(['route','direction_wmata_schedule','tsp_period'])['tot_secs_med']\r\n",
    "    .transform(lambda x: x / x.sum())\r\n",
    ")\r\n",
    "\r\n",
    "rawnav_run_decomp_agg_pivot = (\r\n",
    "    rawnav_run_decomp_agg\r\n",
    "    .pivot(\r\n",
    "            index = ['route','direction_wmata_schedule','full_decomp'],\r\n",
    "            columns = 'tsp_period',\r\n",
    "            values = ['n_count','tot_secs_med','tot_secs_pct']\r\n",
    "    )\r\n",
    "    .pipe(wr.reset_col_names)\r\n",
    "    .assign(\r\n",
    "        tot_secs_med_pre_tsp = lambda x: round(x.tot_secs_med_pre_tsp),\r\n",
    "        tot_secs_med_post_tsp = lambda x: round(x.tot_secs_med_post_tsp),\r\n",
    "        tot_secs_med_diff = lambda x: round(x.tot_secs_med_post_tsp - x.tot_secs_med_pre_tsp),\r\n",
    "        tot_secs_pp_diff = lambda x: round((x.tot_secs_pct_post_tsp - x.tot_secs_pct_pre_tsp) * 100).astype(str) + \"pp\",  \r\n",
    "        tot_secs_pct_pre_tsp = lambda x: (round(x.tot_secs_pct_pre_tsp * 100)).astype(str) + \"%\",\r\n",
    "        tot_secs_pct_post_tsp = lambda x: round(x.tot_secs_pct_post_tsp * 100).astype(str) + \"%\",\r\n",
    "    )\r\n",
    "    .reindex(\r\n",
    "        columns = [\r\n",
    "            \"route\",\r\n",
    "            \"direction_wmata_schedule\",\r\n",
    "            \"full_decomp\",\r\n",
    "            \"n_count_pre_tsp\",\r\n",
    "            \"n_count_post_tsp\",\r\n",
    "            \"tot_secs_med_pre_tsp\",\r\n",
    "            \"tot_secs_med_post_tsp\", \r\n",
    "            \"tot_secs_med_diff\",\r\n",
    "            \"tot_secs_pct_pre_tsp\",\r\n",
    "            \"tot_secs_pct_post_tsp\",\r\n",
    "            \"tot_secs_pp_diff\"\r\n",
    "        ]\r\n",
    "    )\r\n",
    "    .rename(\r\n",
    "        columns = {\r\n",
    "            \"tot_secs_med_post_tsp\" : \"Median Total Seconds (Post TSP)\",\r\n",
    "            \"tot_secs_med_pre_tsp\" : \"Median Total Seconds (Pre TSP)\",\r\n",
    "            \"tot_secs_med_diff\" : \"Change in Median Total Seconds (Pre to Post)\",\r\n",
    "            \"tot_secs_pct_pre_tsp\": \"Percentage of Total Time (Pre TSP)\",\r\n",
    "            \"tot_secs_pct_post_tsp\" : \"Percentage of Total Time (Post TSP)\",\r\n",
    "            \"tot_secs_pp_diff\" : \"Percentage Point Change in Total Time (Pre to Post)\"\r\n",
    "        }\r\n",
    "    )\r\n",
    ")\r\n",
    "\r\n",
    "rawnav_run_decomp_agg.to_csv(r\"rawnav_run_decomp_agg.csv\")\r\n",
    "\r\n",
    "rawnav_run_decomp_agg_pivot"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def stacked_bar(\r\n",
    "    fig_data\r\n",
    "):\r\n",
    "    fig = go.Figure()\r\n",
    "\r\n",
    "    fig.update_layout(\r\n",
    "        template=\"simple_white\",\r\n",
    "        xaxis=dict(title_text=\"Route & Direction\"),\r\n",
    "        yaxis=dict(title_text=\"Total Seconds (Median Values)\"),\r\n",
    "        barmode=\"stack\",\r\n",
    "        font=dict(\r\n",
    "            size=18\r\n",
    "        )\r\n",
    "    )\r\n",
    "\r\n",
    "    fig_data = (\r\n",
    "        fig_data\r\n",
    "        .assign(\r\n",
    "            color = lambda x: \r\n",
    "                np.select(\r\n",
    "                    [\r\n",
    "                        x.full_decomp == \"<5 mph\",\r\n",
    "                        x.full_decomp == \">= 5mph\",\r\n",
    "                        x.full_decomp == \"Delay\",\r\n",
    "                        x.full_decomp == \"Freeflow\",\r\n",
    "                        x.full_decomp == \"Passenger\"\r\n",
    "                    ],\r\n",
    "                    [\r\n",
    "                      \"#440154\",  # <5mph\r\n",
    "                      \"#21908C\", # >=5mph\r\n",
    "                      \"#9C179E\", # delay\r\n",
    "                      \"#FDE725\", # freeflow\r\n",
    "                      '#ED7953' # pax  \r\n",
    "                    ]\r\n",
    "                )\r\n",
    "        )\r\n",
    "    )\r\n",
    "\r\n",
    "    colors = [\r\n",
    "        \"#440154\",  # <5mph\r\n",
    "        \"#21908C\", # >=5mph\r\n",
    "        \"#9C179E\", # delay\r\n",
    "        \"#FDE725\", # freeflow\r\n",
    "        '#ED7953' # pax  \r\n",
    "    ]\r\n",
    "\r\n",
    "    # colors = fig_data.color.unique().tolist\r\n",
    "    # colors_ordered = [y for x in color_order for y in colors if y == x ]\r\n",
    "\r\n",
    "    for r, c in zip(fig_data.full_decomp.unique(), colors):\r\n",
    "        plot_df = fig_data[fig_data.full_decomp == r]\r\n",
    "        fig.add_trace(\r\n",
    "            go.Bar(x=[plot_df.route_dir, plot_df.tsp_period], y=plot_df.tot_secs_med, name=r, marker_color=c),\r\n",
    "        )\r\n",
    "    \r\n",
    "    return(fig)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig1_chart_data = (\r\n",
    "    rawnav_run_decomp_agg\r\n",
    "    .assign(\r\n",
    "        route_dir = lambda x: x.route + \" \" + x.direction_wmata_schedule\r\n",
    "    )\r\n",
    "    .sort_values(by = ['route','direction_wmata_schedule','tsp_period'],ascending = [True,True,False])\r\n",
    ")\r\n",
    "\r\n",
    "fig1 = stacked_bar(fig1_chart_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "py.offline.iplot(fig1, filename='Route Breakdown')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As an early preview of our diff-in-diff results, let's aggregate by is_tsp_route and tsp_period. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rawnav_run_slow = (\r\n",
    "    rawnav_run_decomp_trip_2 \r\n",
    "    # let's first summarize to trip level \r\n",
    "    .loc[\r\n",
    "        (rawnav_run_decomp_trip_2.tsp_dir_time == True) & \r\n",
    "        (rawnav_run_decomp_trip_2.full_decomp == \"<5 mph\")\r\n",
    "    ]\r\n",
    "    .drop(['tsp_dir_time'], axis = 'columns')\r\n",
    "    .assign(\r\n",
    "        route_names = lambda x:\r\n",
    "            np.where(\r\n",
    "                x.is_tsp_route,\r\n",
    "                \"30N/30S/33\",\r\n",
    "                \"31\"\r\n",
    "            )\r\n",
    "    )\r\n",
    "    .groupby(['route_names','tsp_period'])\r\n",
    "    .agg(\r\n",
    "        tot_secs = ('tot_secs','mean')\r\n",
    "    )\r\n",
    "    .reset_index()\r\n",
    "    .pivot(\r\n",
    "            index = ['tsp_period'],\r\n",
    "            columns = 'route_names',\r\n",
    "            values = ['tot_secs']\r\n",
    "    )\r\n",
    "    .reindex(['pre_tsp','post_tsp'])\r\n",
    ")\r\n",
    "\r\n",
    "rawnav_run_slow"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We haven't sorted the above table, but this nets out to 0. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rawnav_run_slow = (\r\n",
    "    rawnav_run_decomp_trip_2 \r\n",
    "    # let's first summarize to trip level \r\n",
    "    .loc[\r\n",
    "        (rawnav_run_decomp_trip_2.tsp_dir_time == True) & \r\n",
    "        (rawnav_run_decomp_trip_2.full_decomp == \"Delay\")\r\n",
    "    ]\r\n",
    "    .drop(['tsp_dir_time'], axis = 'columns')\r\n",
    "    .assign(\r\n",
    "        route_names = lambda x:\r\n",
    "            np.where(\r\n",
    "                x.is_tsp_route,\r\n",
    "                \"30N/30S/33\",\r\n",
    "                \"31\"\r\n",
    "            )\r\n",
    "    )\r\n",
    "    .groupby(['route_names','tsp_period'])\r\n",
    "    .agg(\r\n",
    "        tot_secs = ('tot_secs','mean')\r\n",
    "    )\r\n",
    "    .reset_index()\r\n",
    "    .pivot(\r\n",
    "            index = ['tsp_period'],\r\n",
    "            columns = 'route_names',\r\n",
    "            values = ['tot_secs']\r\n",
    "    )\r\n",
    "    .reindex(['pre_tsp','post_tsp'])\r\n",
    ")\r\n",
    "\r\n",
    "rawnav_run_slow"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rawnav_run_motion = (\r\n",
    "    rawnav_run_decomp_trip_2 \r\n",
    "    # let's first summarize to trip level \r\n",
    "    .loc[\r\n",
    "        (rawnav_run_decomp_trip_2.tsp_dir_time == True) & \r\n",
    "        (rawnav_run_decomp_trip_2.full_decomp.isin([\"<5 mph\",\">= 5mph\"]))\r\n",
    "    ]\r\n",
    "    .assign(\r\n",
    "        route_names = lambda x:\r\n",
    "            np.where(\r\n",
    "                x.is_tsp_route,\r\n",
    "                \"30N/30S/33\",\r\n",
    "                \"31\"\r\n",
    "            )\r\n",
    "    )\r\n",
    "    .drop(['tsp_dir_time'], axis = 'columns')\r\n",
    "    .groupby(['route_names','tsp_period'])\r\n",
    "    .agg(\r\n",
    "        tot_secs = ('tot_secs','mean')\r\n",
    "    )\r\n",
    "    .reset_index()\r\n",
    "    .pivot(\r\n",
    "            index = ['tsp_period'],\r\n",
    "            columns = 'route_names',\r\n",
    "            values = ['tot_secs']\r\n",
    "    ) \r\n",
    "    .reindex(['pre_tsp','post_tsp'])\r\n",
    ")\r\n",
    "\r\n",
    "rawnav_run_motion"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Stop Segment Level\r\n",
    "\r\n",
    "What if we look at particular stop segments?\r\n",
    "\r\n",
    "Note - we haven't looked closely at this.\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# THIS TRIP SEG \r\n",
    "rawnav_run_decomp_trip_stop = (\r\n",
    "    rawnav_run_decomp_2 \r\n",
    "    .groupby(\r\n",
    "        ['filename','index_run_start',\r\n",
    "        'trip_seg',\r\n",
    "        'full_decomp']\r\n",
    "    )\r\n",
    "    .agg(\r\n",
    "        # TODO: this is a confusing naming scheme, should revisit\r\n",
    "        tot_secs = ('secs_tot','sum')\r\n",
    "    )\r\n",
    "    .reset_index()\r\n",
    "    .merge(\r\n",
    "        trip_details,\r\n",
    "        on = ['filename','index_run_start'],\r\n",
    "        how = 'left'\r\n",
    "    )\r\n",
    "    .groupby(['route','direction_wmata_schedule','trip_seg','tsp_period', 'full_decomp'])\r\n",
    "    .agg(\r\n",
    "        {'tot_secs' : [lambda x: x.quantile(.50)]}\r\n",
    "    )\r\n",
    "    .pipe(wr.reset_col_names)\r\n",
    "    .rename(columns = {\"tot_secs_<lambda>\":\"tot_secs_med\"})\r\n",
    ")\r\n",
    "\r\n",
    "rawnav_run_decomp_trip_stop"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rawnav_run_decomp_trip_stop.to_csv(\"rawnav_run_decomp_trip_stop.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculating effect sizes\r\n",
    "\r\n",
    "We'll look at the possible effects of TSP on both stop-level delay and the amount of time spent traveling at less than 5 mph. \r\n",
    "\r\n",
    "### Comparing Pre- and Post-TSP DID\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "slow_speed = (\r\n",
    "    rawnav_run_decomp_trip_2 \r\n",
    "    .loc[\r\n",
    "        (\r\n",
    "            (rawnav_run_decomp_trip_2.tsp_dir_time == True) #|\r\n",
    "            # (rawnav_run_decomp_trip_2.tsp_offdir_time == True) #we'll reintroduce this later i think\r\n",
    "        ) &\r\n",
    "        (rawnav_run_decomp_trip_2.full_decomp == \"<5 mph\")\r\n",
    "    ]\r\n",
    "    .assign(\r\n",
    "        is_post_tsp = lambda x: x.tsp_period == \"pre_tsp\"\r\n",
    "    )\r\n",
    ")\r\n",
    "\r\n",
    "slow_speed.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "smf.ols('tot_secs ~ is_tsp_route*is_post_tsp', data = slow_speed).fit().summary().tables[1] # want to add overall_dir when that's raeady"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hmm, it's looking like there is no detectable effect of TSP after it's introduced. We could try implementing a few more controls, but it's not looking promising. Many of these controls are going to be collinear with having tsp (routes and time_period with is_tsp_route), which will make any t statistic a little harder to interpret"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "smf.ols('tot_secs ~ is_tsp_route*is_post_tsp + route + time_period', data = slow_speed).fit().summary().tables[1] # want to add overall_dir when that's raeady"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "What about delay ?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "delay_time = (\r\n",
    "    rawnav_run_decomp_trip_2 \r\n",
    "    .loc[\r\n",
    "        (\r\n",
    "            (rawnav_run_decomp_trip_2.tsp_dir_time == True) #|\r\n",
    "            # (rawnav_run_decomp_trip_2.tsp_offdir_time == True) #we'll reintroduce this later i think\r\n",
    "        ) &\r\n",
    "        (rawnav_run_decomp_trip_2.full_decomp == \"Delay\")\r\n",
    "    ]\r\n",
    "    .assign(\r\n",
    "        is_post_tsp = lambda x: x.tsp_period == \"pre_tsp\"\r\n",
    "    )\r\n",
    ")\r\n",
    "\r\n",
    "delay_time.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "smf.ols('tot_secs ~ is_tsp_route*is_post_tsp', data = delay_time).fit().summary().tables[1] "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A little confusing because the base category is True in each case, but this says TSP makes things 23 seconds worse on average."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comparing CDF\r\n",
    "\r\n",
    "Let's look at how the distribution of < 5mph travel differs between these trips"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rawnav_cdf_df = (\r\n",
    "    rawnav_run_decomp_trip_2\r\n",
    "    .loc[\r\n",
    "        (rawnav_run_decomp_trip_2.tsp_dir_time == True) & \r\n",
    "        (rawnav_run_decomp_trip_2.is_tsp_route == True) &\r\n",
    "        (rawnav_run_decomp_trip_2.full_decomp == \"<5 mph\")\r\n",
    "    ]\r\n",
    "    .drop(['tsp_dir_time'], axis = 'columns')\r\n",
    "    .sort_values(['is_tsp_route','tot_secs'])\r\n",
    ")\r\n",
    "# https://stackoverflow.com/questions/65402296/python-plotly-cdf-with-frequency-distribution-data\r\n",
    "\r\n",
    "# we'll split this into two for each of the two conditions\r\n",
    "time_vals = rawnav_cdf_df['tot_secs'].values.tolist()\r\n",
    "time_vals_is_tsp_route = rawnav_cdf_df.loc[rawnav_cdf_df.tsp_period == 'post_tsp', 'tot_secs'].values.tolist()\r\n",
    "time_vals_no_tsp = rawnav_cdf_df.loc[rawnav_cdf_df.tsp_period == 'pre_tsp', 'tot_secs'].values.tolist()\r\n",
    "\r\n",
    "hist, bin_edges_all = np.histogram(time_vals, bins = 100, density = True)\r\n",
    "\r\n",
    "hist_is_tsp_route, bin_edges_is_tsp_route = np.histogram(time_vals_is_tsp_route, bins = 100, density = True)\r\n",
    "hist_no_tsp, bin_edges_no_tsp = np.histogram(time_vals_no_tsp, bins = 100, density = True)\r\n",
    "\r\n",
    "cdf_is_tsp_route = np.cumsum(hist_is_tsp_route * np.diff(bin_edges_is_tsp_route))\r\n",
    "cdf_no_tsp = np.cumsum(hist_no_tsp * np.diff(bin_edges_no_tsp))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "fig3 = go.Figure(\r\n",
    "    data=[\r\n",
    "        go.Scatter(x=bin_edges_is_tsp_route, y=cdf_is_tsp_route, name='Post-TSP', marker_color = 'rgba(244,136,118,1)'),\r\n",
    "        go.Scatter(x=bin_edges_no_tsp, y=cdf_no_tsp, name='Pre-TSP', marker_color = 'rgba(146,154,252,1)')\r\n",
    "    ]\r\n",
    ")\r\n",
    "\r\n",
    "fig3.update_layout(\r\n",
    "        template=\"simple_white\",\r\n",
    "        xaxis=dict(title_text=\"Travel Time (Seconds) <5 mph\"),\r\n",
    "        yaxis=dict(title_text=\"Percent of Trips\"),\r\n",
    "        yaxis_tickformat = '%',\r\n",
    "        font=dict(\r\n",
    "            size=18\r\n",
    "        )\r\n",
    "    )\r\n",
    "\r\n",
    "fig3.update_yaxes(\r\n",
    "    showgrid = True,\r\n",
    "    gridwidth = 1,\r\n",
    "    gridcolor = 'rgba(204,204,204,.8)'\r\n",
    ")\r\n",
    "\r\n",
    "fig3.update_xaxes(\r\n",
    "    showgrid = True,\r\n",
    "    gridwidth = 1,\r\n",
    "    gridcolor = 'rgba(204,204,204,.8)'\r\n",
    ")\r\n",
    "\r\n",
    "fig3.update_yaxes(\r\n",
    "    tickvals=[0.0,.05, .25, .50, .75, .95, 1.00]\r\n",
    ")\r\n",
    "\r\n",
    "py.offline.iplot(fig3, filename='CDF')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "These values below should match the ones in our cross tab from before"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.mean(time_vals_is_tsp_route)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.mean(time_vals_no_tsp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "These values should approximately correspond to things we see in the chart"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.quantile(time_vals_is_tsp_routeroute,.95) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "np.quantile(time_vals_no_tsp,.95)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9fd0b08f9fa72feef383850fc190106f7c37a1cf0a0377a8c1402f673c9ab5a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('datamart6': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}