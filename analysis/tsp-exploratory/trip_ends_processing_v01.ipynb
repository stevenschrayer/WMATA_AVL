{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-23T12:55:43.991392Z",
     "iopub.status.busy": "2021-07-23T12:55:43.991392Z",
     "iopub.status.idle": "2021-07-23T12:55:45.904396Z",
     "shell.execute_reply": "2021-07-23T12:55:45.904396Z",
     "shell.execute_reply.started": "2021-07-23T12:55:43.991392Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_access as mdb\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pyodbc\n",
    "import geopandas as gpd\n",
    "import itertools\n",
    "import folium\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = 75\n",
    "pd.options.display.max_rows = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-23T12:55:45.906398Z",
     "iopub.status.busy": "2021-07-23T12:55:45.905398Z",
     "iopub.status.idle": "2021-07-23T12:55:45.922405Z",
     "shell.execute_reply": "2021-07-23T12:55:45.920409Z",
     "shell.execute_reply.started": "2021-07-23T12:55:45.906398Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_time():\n",
    "    \"\"\"\n",
    "    Returns current timestamp.\n",
    "    \"\"\"\n",
    "    return datetime.now().strftime(\"%m-%d-%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-23T12:55:47.191166Z",
     "iopub.status.busy": "2021-07-23T12:55:47.190164Z",
     "iopub.status.idle": "2021-07-23T12:55:47.202163Z",
     "shell.execute_reply": "2021-07-23T12:55:47.202163Z",
     "shell.execute_reply.started": "2021-07-23T12:55:47.191166Z"
    }
   },
   "outputs": [],
   "source": [
    "months = [202103, 202104]\n",
    "routes = ['30N', '30S', '31', '33']\n",
    "days = ['Tuesday']\n",
    "directions = ['EAST', 'SOUTH']\n",
    "start_time = '05:00:00'\n",
    "end_time = '10:00:00'\n",
    "CRS = 'EPSG:4326'\n",
    "distance_thresh = 400\n",
    "duration_thresh = 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-23T12:55:50.582912Z",
     "iopub.status.busy": "2021-07-23T12:55:50.581911Z",
     "iopub.status.idle": "2021-07-23T12:55:50.861909Z",
     "shell.execute_reply": "2021-07-23T12:55:50.860909Z",
     "shell.execute_reply.started": "2021-07-23T12:55:50.582912Z"
    }
   },
   "outputs": [],
   "source": [
    "root_directory = os.path.normpath(r'C:\\Users\\amondal\\OneDrive - Cambridge Systematics\\CS PROJECTS\\WMATA Bus Priority\\data\\tsp_exploratory')\n",
    "\n",
    "path_repo = os.path.join(r'C:\\Users\\amondal\\OneDrive - Cambridge Systematics\\CS PROJECTS\\WMATA Bus Priority\\codebase\\WMATA_AVL')\n",
    "sys.path.append(path_repo)\n",
    "\n",
    "# Import wmatarawnav library\n",
    "import wmatarawnav as wr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read rawnav data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-23T12:55:51.207911Z",
     "iopub.status.busy": "2021-07-23T12:55:51.206917Z",
     "iopub.status.idle": "2021-07-23T12:56:00.205129Z",
     "shell.execute_reply": "2021-07-23T12:56:00.203940Z",
     "shell.execute_reply.started": "2021-07-23T12:55:51.207911Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_rawnav_parquet(root_directory, month, routes, days):\n",
    "    return (wr.read_cleaned_rawnav(analysis_routes_= routes,\n",
    "                                   analysis_days_ = days,\n",
    "                                   path = os.path.join(root_directory, 'rawnav_data_wisconsin', f'rawnav_data_{month}.parquet')))\n",
    "\n",
    "data = pd.concat([read_rawnav_parquet(root_directory, month, routes, days) for month in months])\n",
    "\n",
    "# Sort data by `start_date_time`, `route`, and `index_loc`\n",
    "data = data.sort_values(by = ['start_date_time', 'route', 'index_loc'])\n",
    "\n",
    "# Apply filters | AM Peak (5 am - 10 am)\n",
    "data = data.set_index('start_date_time').between_time(start_time, end_time, include_end = False).reset_index()\n",
    "\n",
    "# Create unique trip ID\n",
    "data['trip_id'] = data.index_run_start.astype(int).astype(str) + ' - ' + data.filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read and process schedule database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-23T12:56:10.471246Z",
     "iopub.status.busy": "2021-07-23T12:56:10.470244Z",
     "iopub.status.idle": "2021-07-23T12:56:10.851244Z",
     "shell.execute_reply": "2021-07-23T12:56:10.850244Z",
     "shell.execute_reply.started": "2021-07-23T12:56:10.470244Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up connection to WMATA Schedule database\n",
    "# Create cursor object\n",
    "\n",
    "schedule_filename = 'Schedule_082719-201718.mdb'\n",
    "database_path = os.path.join(root_directory, 'wmata_schedule', schedule_filename)\n",
    "connection = pyodbc.connect(r'Driver={Microsoft Access Driver (*.mdb, *.accdb)};DBQ=' + database_path)\n",
    "cursor = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-23T12:56:10.910247Z",
     "iopub.status.busy": "2021-07-23T12:56:10.910247Z",
     "iopub.status.idle": "2021-07-23T12:56:11.807248Z",
     "shell.execute_reply": "2021-07-23T12:56:11.806284Z",
     "shell.execute_reply.started": "2021-07-23T12:56:10.910247Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read required tables\n",
    "\n",
    "pattern = pd.read_sql(sql = 'SELECT * FROM Pattern', con = connection)\n",
    "stop = pd.read_sql(sql = 'SELECT * FROM Stop', con = connection)\n",
    "stop_info = pd.read_sql(sql = 'SELECT * FROM StopInfo', con = connection)\n",
    "stop_list = pd.read_sql(sql = 'SELECT * FROM StopList', con = connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-23T12:56:11.808248Z",
     "iopub.status.busy": "2021-07-23T12:56:11.808248Z",
     "iopub.status.idle": "2021-07-23T12:56:11.823250Z",
     "shell.execute_reply": "2021-07-23T12:56:11.822248Z",
     "shell.execute_reply.started": "2021-07-23T12:56:11.808248Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select required columns in each table\n",
    "\n",
    "pattern = pattern[['PatternID', 'TARoute', 'PatternName', 'CDVariation', 'Direction', 'Distance', 'RouteKey']]\n",
    "stop = stop[['GeoID', 'GeoDescription', 'Longitude', 'Latitude']]\n",
    "stop_info = stop_info[['StopID', 'StopDesc']]\n",
    "stop_list = stop_list[['RouteKey', 'StopSequence', 'StopID', 'GeoID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-23T12:56:11.894250Z",
     "iopub.status.busy": "2021-07-23T12:56:11.893248Z",
     "iopub.status.idle": "2021-07-23T12:56:11.918250Z",
     "shell.execute_reply": "2021-07-23T12:56:11.917251Z",
     "shell.execute_reply.started": "2021-07-23T12:56:11.894250Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter and merge datasets\n",
    "\n",
    "pattern = pattern[pattern.TARoute.isin(routes)].sort_values(by = ['TARoute', 'CDVariation'])\n",
    "stops = stop_list.merge(stop, on = 'GeoID', how = 'left')\n",
    "stops = stops[stops.RouteKey.isin(pattern.RouteKey.unique())].sort_values(by = ['RouteKey', 'StopSequence'])\n",
    "stops = pattern.merge(stops, on = 'RouteKey', how = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-23T12:56:15.278724Z",
     "iopub.status.busy": "2021-07-23T12:56:15.277721Z",
     "iopub.status.idle": "2021-07-23T12:56:15.285718Z",
     "shell.execute_reply": "2021-07-23T12:56:15.284716Z",
     "shell.execute_reply.started": "2021-07-23T12:56:15.278724Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create route_pattern column to merge with rawnav\n",
    "stops['route_pattern'] = stops.TARoute.astype(str) + stops.CDVariation.astype(str).str.zfill(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-23T12:56:18.102181Z",
     "iopub.status.busy": "2021-07-23T12:56:18.102181Z",
     "iopub.status.idle": "2021-07-23T12:56:19.804205Z",
     "shell.execute_reply": "2021-07-23T12:56:19.803186Z",
     "shell.execute_reply.started": "2021-07-23T12:56:18.102181Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove whitespaces from route_pattern columns in rawnav data\n",
    "# Merge route pattern to get Direction\n",
    "\n",
    "data['route_pattern'] = data['route_pattern'].str.strip()\n",
    "data = data.merge(stops[['route_pattern', 'Distance', 'Direction']].drop_duplicates(keep = 'first'),\n",
    "                  on = 'route_pattern',\n",
    "                  how = 'left')\n",
    "\n",
    "# Filter by direction only\n",
    "data = data[data.Direction.isin(directions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-23T12:57:18.611120Z",
     "iopub.status.busy": "2021-07-23T12:57:18.611120Z",
     "iopub.status.idle": "2021-07-23T12:57:18.767121Z",
     "shell.execute_reply": "2021-07-23T12:57:18.766119Z",
     "shell.execute_reply.started": "2021-07-23T12:57:18.611120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "route_pattern\n",
       "30N02     45\n",
       "30S02     46\n",
       "3101     122\n",
       "3301     159\n",
       "Name: trip_id, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['route_pattern'])['trip_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import TSP Intersection Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-23T12:57:58.024162Z",
     "iopub.status.busy": "2021-07-23T12:57:58.024162Z",
     "iopub.status.idle": "2021-07-23T12:57:58.929161Z",
     "shell.execute_reply": "2021-07-23T12:57:58.928196Z",
     "shell.execute_reply.started": "2021-07-23T12:57:58.024162Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import TSP intersection coordinates and convert to GeoDataFrame\n",
    "tsp_int = (pd.read_excel(os.path.join(root_directory, \n",
    "                                     'tsp_intersections', \n",
    "                                     'wisconsin_tsp_intersections.xlsx'),\n",
    "                       sheet_name = 'tsp_intersections')\n",
    "           .rename(columns = {'Intersection ' : 'intersection', 'xcoor' : 'int_long', 'ycoor' : 'int_lat'})\n",
    "           .dropna(subset = ['intersection']))[['intersection', 'int_lat', 'int_long']]\n",
    "\n",
    "tsp_int = gpd.GeoDataFrame(tsp_int, \n",
    "                           geometry = gpd.points_from_xy(tsp_int.int_long, tsp_int.int_lat),\n",
    "                           crs = CRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-29T21:40:13.518788Z",
     "iopub.status.busy": "2021-06-29T21:40:13.518788Z",
     "iopub.status.idle": "2021-06-29T21:40:13.694391Z",
     "shell.execute_reply": "2021-06-29T21:40:13.693390Z",
     "shell.execute_reply.started": "2021-06-29T21:40:13.518788Z"
    }
   },
   "source": [
    "#### Plot Intersection Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_points_on_map(gdf, y_col, x_col, label, radius = 25, color = 'crimson'):\n",
    "    \n",
    "    map_with_points = folium.Map(location = [gdf[y_col].mean(), gdf[x_col].mean()],\n",
    "                                 #tiles = \"Stamen Toner\", \n",
    "                                 zoom_start = 15)\n",
    "    # Add points\n",
    "    for ix, row in gdf.iterrows():\n",
    "        folium.Circle(radius = radius,\n",
    "                      location = [row[y_col], row[x_col]],\n",
    "                      popup = row[label],\n",
    "                      color = color,\n",
    "                      fill = False).add_to(map_with_points)\n",
    "    return map_with_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "plot_points_on_map(gdf = tsp_int, \n",
    "                   x_col = 'int_long', \n",
    "                   y_col = 'int_lat', \n",
    "                   label = 'intersection')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trip Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://gis.stackexchange.com/questions/222315/geopandas-find-nearest-point-in-other-dataframe\n",
    "def get_nearest_point(gdA, gdB):\n",
    "    '''\n",
    "    Find the nearest point from gdB for \n",
    "    each point in gdA.  \n",
    "    '''\n",
    "    nA = np.array(list(gdA.geometry.apply(lambda x: (x.x, x.y))))\n",
    "    nB = np.array(list(gdB.geometry.apply(lambda x: (x.x, x.y))))\n",
    "    btree = cKDTree(nB)\n",
    "    dist, idx = btree.query(nA, k = 1)\n",
    "    gdB_nearest = gdB.iloc[idx].drop(columns = 'geometry').reset_index(drop = True)\n",
    "    gdf = pd.concat([gdA.reset_index(drop=True), gdB_nearest, pd.Series(dist, name = 'dist')], axis=1)\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict2_to_df(dictionary, col_name_1, col_name_2, col_name_3):\n",
    "    '''\n",
    "    Creates a Pandas DataFrame from \n",
    "    2-layer nested dictionary.\n",
    "    '''\n",
    "    df = (pd.concat({k: pd.DataFrame.from_dict(v, orient = 'index') for k, v in dictionary.items()})\n",
    "          .reset_index()\n",
    "          .rename(columns = {'level_0' : col_name_1, 'level_1' : col_name_2, 0 : col_name_3}))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_geo_dataframe(df, longitude_col, latitude_col, crs):\n",
    "    '''\n",
    "    Create a GeoDataFrame from a Pandas DataFrame\n",
    "    with longitude and longitude of points.\n",
    "    '''\n",
    "    import geopandas as gpd\n",
    "    return gpd.GeoDataFrame(df, \n",
    "                            geometry = gpd.points_from_xy(df[longitude_col], df[latitude_col]),\n",
    "                            crs = CRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Stops and RAWNAV GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = create_geo_dataframe(df = stops, \n",
    "                             longitude_col = 'Longitude', \n",
    "                             latitude_col = 'Latitude', \n",
    "                             crs = CRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_geo_dataframe(df = data,\n",
    "                            longitude_col = 'long',\n",
    "                            latitude_col = 'lat',\n",
    "                            crs = CRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Trip Start Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pings_before_first_stop_window(data, unique_trip_id_col, first_stop_entry_point = 'E00', first_stop_exit_point = 'X-1'):\n",
    "    \"\"\"\n",
    "    Remove pings that are recorded before the exit point\n",
    "    of the first stop window. This is done in multiple steps\n",
    "    to improve computational efficiency.\n",
    "    \n",
    "    Steps:\n",
    "    ------\n",
    "    - Remove the trips that do not have first stop window entry tag.\n",
    "    - Identify the entry point of first stop window.\n",
    "    - Remove the records before the entry point of first stop window.\n",
    "    - Identify the exit point of first stop window.\n",
    "    - Remove the trips that do not have stop window exit tag.\n",
    "    - Remove the records before the exit point of first stop window.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove the trips that do not have first stop window entry tag.\n",
    "    data = (data[data[unique_trip_id_col]\n",
    "                 .isin(data[data.stop_window == first_stop_entry_point][unique_trip_id_col].unique())])\n",
    "    \n",
    "    # Identify the entry point of first stop window.\n",
    "    df = (data[data.stop_window == first_stop_entry_point]\n",
    "          .groupby([unique_trip_id_col, 'stop_window'])['index_loc']\n",
    "          .agg(['min'])\n",
    "          .add_prefix('fsw_entry_index_loc_')\n",
    "          .sort_index()\n",
    "          .reset_index())\n",
    "    \n",
    "    data = data.merge(df.drop(columns = ['stop_window']),\n",
    "                      on = unique_trip_id_col,\n",
    "                      how = 'left').sort_values(by = ['start_date_time', 'route', 'index_loc'])\n",
    "    \n",
    "    # Remove the records before the entry point of first stop window.\n",
    "    data[data.index_loc >= data.fsw_entry_index_loc_min]\n",
    "    \n",
    "    # Identify the exit point of first stop window. \n",
    "    df2 = (data[data.stop_window == first_stop_exit_point]\n",
    "            .groupby([unique_trip_id_col, 'stop_window'])['index_loc']\n",
    "            .agg(['min'])\n",
    "            .add_prefix('fsw_exit_index_loc_')\n",
    "            .sort_index()\n",
    "            .reset_index())\n",
    "    \n",
    "    # Remove the trips that do not have stop window exit tag.\n",
    "    data = data[data[unique_trip_id_col].isin(df2[unique_trip_id_col].unique())]\n",
    "    data = data.merge(df2.drop(columns = ['stop_window']),\n",
    "                      on = unique_trip_id_col,\n",
    "                      how = 'left').sort_values(by = ['start_date_time', 'route', 'index_loc'])\n",
    "    \n",
    "    # Remove the records before the exit point of first stop window.\n",
    "    data = data[data.index_loc >= data.fsw_exit_index_loc_min]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove pings that are recorded before the entry point\n",
    "# of the first stop window.\n",
    "data = remove_pings_before_first_stop_window(data = data, \n",
    "                                             unique_trip_id_col = 'trip_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Trip End Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pings_after_last_stop_window(data, unique_trip_id_col):\n",
    "    \"\"\"\n",
    "    Remove pings that are recorded after the entry point\n",
    "    of the last stop window. This is done in multiple steps\n",
    "    to improve computational efficiency.\n",
    "    \n",
    "    Steps:\n",
    "    ------\n",
    "    - Create dummy variable for stop window entry tag.\n",
    "    - Identify the entry point of last stop window.\n",
    "    - Remove the trips that do not have last stop window entry tag.\n",
    "    - Remove the records after the entry point of last stop window.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create dummy variable for stop window entry tag.\n",
    "    data.loc[data['stop_window'].str[0] == 'E', 'sw_entry_marker'] = 'E'\n",
    "    \n",
    "    # Identify the entry point of last stop window.\n",
    "    df = (data.groupby([unique_trip_id_col, 'sw_entry_marker'])['index_loc']\n",
    "          .agg(['max'])\n",
    "          .add_prefix('lsw_entry_index_loc_')\n",
    "          .sort_index()\n",
    "          .reset_index())\n",
    "    \n",
    "    # Remove the trips that does not have last stop window entry tag.\n",
    "    data = data[data[unique_trip_id_col].isin(df[unique_trip_id_col].unique())]\n",
    "    data = data.merge(df.drop(columns = ['sw_entry_marker']),\n",
    "                  on = unique_trip_id_col,\n",
    "                  how = 'left').sort_values(by = ['start_date_time', 'route', 'index_loc'])\n",
    "    \n",
    "    # Remove the records after the entry point of last stop window.\n",
    "    data = data[data.index_loc <= data.lsw_entry_index_loc_max]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove pings that are recorded after the entry point\n",
    "# of the last stop window.\n",
    "data = remove_pings_after_last_stop_window(data = data, unique_trip_id_col = 'trip_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reset Odometer and Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_odometer_timer(data, unique_trip_id_col = 'trip_id'):\n",
    "    \"\"\"\n",
    "    Reset odometer and timer reading based on the start \n",
    "    and end point of each trip. \n",
    "    \"\"\"\n",
    "    df = (data.groupby([unique_trip_id_col])['odom_ft'].agg(['min']).add_prefix('odom_ft_')\n",
    "          .join(data.groupby([unique_trip_id_col])['sec_past_st'].agg(['min']).add_prefix('sec_past_st_')).reset_index())\n",
    "    \n",
    "    data = data.merge(df, on = unique_trip_id_col, how = 'left')\n",
    "    \n",
    "    # Create new columns with adjusted variables.\n",
    "    data['adj_odom_ft'] = data['odom_ft'] - data['odom_ft_min']\n",
    "    data['adj_dur_sec'] = data['sec_past_st'] - data['sec_past_st_min']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset odometer and timer\n",
    "data = reset_odometer_timer(data = data, unique_trip_id_col = 'trip_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select Trips based on Median Distance and Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_trips_based_on_dist_dur(data, unique_trip_id_col, adj_odom_col, adj_dur_col, agg_func, distance_thresh, duration_thresh):\n",
    "    \"\"\"\n",
    "    Select trips that have distance and duration within \n",
    "    certain range of aggregate values of those measures\n",
    "    for each route-pattern combination.\n",
    "    \"\"\"\n",
    "    trip_sel_df = (data.groupby(['route_pattern', unique_trip_id_col])[adj_odom_col, adj_dur_col].max()\n",
    "                   .reset_index().set_index('route_pattern'))\n",
    "    trip_sel_df = trip_sel_df.join(data.drop(columns = ['trip_id'])[['route_pattern', adj_odom_col, adj_dur_col]]\n",
    "                                   .groupby(['route_pattern'])\n",
    "                                   .quantile(0.99).add_prefix('agg_'))\n",
    "\n",
    "\n",
    "    # Selection criteria\n",
    "    select_criteria = ((trip_sel_df[adj_odom_col] > trip_sel_df[f'agg_{adj_odom_col}'] - distance_thresh) &\n",
    "                       (trip_sel_df[adj_odom_col] < trip_sel_df[f'agg_{adj_odom_col}'] + distance_thresh) &\n",
    "                       (trip_sel_df[adj_dur_col] < trip_sel_df[f'agg_{adj_dur_col}'] * duration_thresh))\n",
    "    trip_sel_df['selection_flag'] = 1 * select_criteria\n",
    "    \n",
    "    return trip_sel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please use this function with caution. This is not properly tested.\n",
    "trip_sel_df = select_trips_based_on_dist_dur(data = data,\n",
    "                                             unique_trip_id_col = 'trip_id',\n",
    "                                             adj_odom_col = 'adj_odom_ft', \n",
    "                                             adj_dur_col = 'adj_dur_sec', \n",
    "                                             agg_func = np.median, \n",
    "                                             distance_thresh = distance_thresh, \n",
    "                                             duration_thresh = duration_thresh).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select trips\n",
    "data = data[data.trip_id.isin(trip_sel_df[trip_sel_df.selection_flag == 1].trip_id.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
